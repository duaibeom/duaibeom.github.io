{"type":"data","nodes":[null,{"type":"data","data":[{"prev":1,"next":4,"section":7},{"slug":2,"title":3},"blog\u002Fmake_blog","블로그 생성",{"slug":5,"title":6},"blog\u002Finstruct_gpt","InstructGPT",{"file":8,"title":9,"date":10,"summary":11,"tag":12,"toc":15,"body":16},"blog\u002F15-ai_safety.md","AI Safety","Feb. 8, 2023","reliable and honest ML",[13,14],"ml","ethic","\u003Ch4\u003EContents\u003C\u002Fh4\u003E\u003Cp class=\"toc-h2\"\u003E\u003Ca href=\"#ai-alignment\"\u003EAI alignment\u003C\u002Fa\u003E\u003C\u002Fp\u003E\u003Cp class=\"toc-h3\"\u003E\u003Ca href=\"#learning-values-by-asking-humans-questions\"\u003E\u003Cstrong\u003ELearning values by asking humans questions\u003C\u002Fstrong\u003E\u003C\u002Fa\u003E\u003C\u002Fp\u003E\u003Cp class=\"toc-h3\"\u003E\u003Ca href=\"#definitions-of-alignment-reasoning-and-reflective-equilibrium\"\u003E\u003Cstrong\u003EDefinitions of alignment: reasoning and reflective equilibrium\u003C\u002Fstrong\u003E\u003C\u002Fa\u003E\u003C\u002Fp\u003E\u003Cp class=\"toc-h3\"\u003E\u003Ca href=\"#reference\"\u003E\u003Cstrong\u003EReference\u003C\u002Fstrong\u003E\u003C\u002Fa\u003E\u003C\u002Fp\u003E","\u003Cp\u003E본 글은 distill의 \u003Ca href=\"https:\u002F\u002Fdoi.org\u002F10.23915\u002Fdistill.00014\"\u003EAI Safety Needs Social Scientists\u003C\u002Fa\u003E을 단순 정리한 글입니다.\u003C\u002Fp\u003E\n\u003Cp\u003EThe goal of long-term \u003Cstrong\u003Eartificial intelligence (AI) safety\u003C\u002Fstrong\u003E is to ensure that advanced AI systems are \u003Cstrong\u003Ereliably aligned with human values\u003C\u002Fstrong\u003E — that they reliably do things that people want them to do.\u003C\u002Fp\u003E\n\u003Cp\u003E만약 정말 잘 학습된 (정의된 목적 값을 잘 따르는) ML 모델이 있다. 모델 설계자가 다양한 모든 질문에 대하여 잘 대비하였다면, 불확실성은 모델에 있을 수 밖에 없다.\u003C\u002Fp\u003E\n\u003Cp\u003E하지만, 인간은 불완전하고, 다양성을 가지고 있다. ML 모델은 human biases를 가질 수 밖에 없다.\u003C\u002Fp\u003E\n\u003Caside\u003E\n\n\u003Cp\u003E💡 ChatGPT에 질문을 더 잘하기 위해서는? \u003Cspan class=\"katex\"\u003E\u003Cspan class=\"katex-mathml\"\u003E\u003Cmath xmlns=\"http:\u002F\u002Fwww.w3.org\u002F1998\u002FMath\u002FMathML\"\u003E\u003Csemantics\u003E\u003Cmrow\u003E\u003Cmsup\u003E\u003Cmrow\u003E\u003Cmi mathvariant=\"bold\"\u003EP\u003C\u002Fmi\u003E\u003Cmo stretchy=\"false\"\u003E(\u003C\u002Fmo\u003E\u003Cmi\u003EQ\u003C\u002Fmi\u003E\u003Cmi mathvariant=\"normal\"\u003E∣\u003C\u002Fmi\u003E\u003Cmi\u003ES\u003C\u002Fmi\u003E\u003Cmo stretchy=\"false\"\u003E)\u003C\u002Fmo\u003E\u003C\u002Fmrow\u003E\u003Cmo\u003E∗\u003C\u002Fmo\u003E\u003C\u002Fmsup\u003E\u003C\u002Fmrow\u003E\u003Cannotation encoding=\"application\u002Fx-tex\"\u003E{{\\bf P}(Q|S)}^*\u003C\u002Fannotation\u003E\u003C\u002Fsemantics\u003E\u003C\u002Fmath\u003E\u003C\u002Fspan\u003E\u003Cspan class=\"katex-html\" aria-hidden=\"true\"\u003E\u003Cspan class=\"base\"\u003E\u003Cspan class=\"strut\" style=\"height:1.0786em;vertical-align:-0.25em;\"\u003E\u003C\u002Fspan\u003E\u003Cspan class=\"mord\"\u003E\u003Cspan class=\"mord\"\u003E\u003Cspan class=\"mord\"\u003E\u003Cspan class=\"mord\"\u003E\u003Cspan class=\"mord mathbf\"\u003EP\u003C\u002Fspan\u003E\u003C\u002Fspan\u003E\u003C\u002Fspan\u003E\u003Cspan class=\"mopen\"\u003E(\u003C\u002Fspan\u003E\u003Cspan class=\"mord mathnormal\"\u003EQ\u003C\u002Fspan\u003E\u003Cspan class=\"mord\"\u003E∣\u003C\u002Fspan\u003E\u003Cspan class=\"mord mathnormal\" style=\"margin-right:0.05764em;\"\u003ES\u003C\u002Fspan\u003E\u003Cspan class=\"mclose\"\u003E)\u003C\u002Fspan\u003E\u003C\u002Fspan\u003E\u003Cspan class=\"msupsub\"\u003E\u003Cspan class=\"vlist-t\"\u003E\u003Cspan class=\"vlist-r\"\u003E\u003Cspan class=\"vlist\" style=\"height:0.8286em;\"\u003E\u003Cspan style=\"top:-3.2029em;margin-right:0.05em;\"\u003E\u003Cspan class=\"pstrut\" style=\"height:2.7em;\"\u003E\u003C\u002Fspan\u003E\u003Cspan class=\"sizing reset-size6 size3 mtight\"\u003E\u003Cspan class=\"mbin mtight\"\u003E∗\u003C\u002Fspan\u003E\u003C\u002Fspan\u003E\u003C\u002Fspan\u003E\u003C\u002Fspan\u003E\u003C\u002Fspan\u003E\u003C\u002Fspan\u003E\u003C\u002Fspan\u003E\u003C\u002Fspan\u003E\u003C\u002Fspan\u003E\u003C\u002Fspan\u003E\u003C\u002Fspan\u003E\u003C\u002Fp\u003E\n\u003Cp\u003EDirect questions about preferences (“Do you prefer \u003Cspan class=\"katex\"\u003E\u003Cspan class=\"katex-mathml\"\u003E\u003Cmath xmlns=\"http:\u002F\u002Fwww.w3.org\u002F1998\u002FMath\u002FMathML\"\u003E\u003Csemantics\u003E\u003Cmrow\u003E\u003Cmi\u003EA\u003C\u002Fmi\u003E\u003C\u002Fmrow\u003E\u003Cannotation encoding=\"application\u002Fx-tex\"\u003EA\u003C\u002Fannotation\u003E\u003C\u002Fsemantics\u003E\u003C\u002Fmath\u003E\u003C\u002Fspan\u003E\u003Cspan class=\"katex-html\" aria-hidden=\"true\"\u003E\u003Cspan class=\"base\"\u003E\u003Cspan class=\"strut\" style=\"height:0.6833em;\"\u003E\u003C\u002Fspan\u003E\u003Cspan class=\"mord mathnormal\"\u003EA\u003C\u002Fspan\u003E\u003C\u002Fspan\u003E\u003C\u002Fspan\u003E\u003C\u002Fspan\u003E or \u003Cspan class=\"katex\"\u003E\u003Cspan class=\"katex-mathml\"\u003E\u003Cmath xmlns=\"http:\u002F\u002Fwww.w3.org\u002F1998\u002FMath\u002FMathML\"\u003E\u003Csemantics\u003E\u003Cmrow\u003E\u003Cmi\u003EB\u003C\u002Fmi\u003E\u003C\u002Fmrow\u003E\u003Cannotation encoding=\"application\u002Fx-tex\"\u003EB\u003C\u002Fannotation\u003E\u003C\u002Fsemantics\u003E\u003C\u002Fmath\u003E\u003C\u002Fspan\u003E\u003Cspan class=\"katex-html\" aria-hidden=\"true\"\u003E\u003Cspan class=\"base\"\u003E\u003Cspan class=\"strut\" style=\"height:0.6833em;\"\u003E\u003C\u002Fspan\u003E\u003Cspan class=\"mord mathnormal\" style=\"margin-right:0.05017em;\"\u003EB\u003C\u002Fspan\u003E\u003C\u002Fspan\u003E\u003C\u002Fspan\u003E\u003C\u002Fspan\u003E?“) may be less accurate than questions which target the reasoning behind these preferences (“Do you prefer \u003Cspan class=\"katex\"\u003E\u003Cspan class=\"katex-mathml\"\u003E\u003Cmath xmlns=\"http:\u002F\u002Fwww.w3.org\u002F1998\u002FMath\u002FMathML\"\u003E\u003Csemantics\u003E\u003Cmrow\u003E\u003Cmi\u003EA\u003C\u002Fmi\u003E\u003C\u002Fmrow\u003E\u003Cannotation encoding=\"application\u002Fx-tex\"\u003EA\u003C\u002Fannotation\u003E\u003C\u002Fsemantics\u003E\u003C\u002Fmath\u003E\u003C\u002Fspan\u003E\u003Cspan class=\"katex-html\" aria-hidden=\"true\"\u003E\u003Cspan class=\"base\"\u003E\u003Cspan class=\"strut\" style=\"height:0.6833em;\"\u003E\u003C\u002Fspan\u003E\u003Cspan class=\"mord mathnormal\"\u003EA\u003C\u002Fspan\u003E\u003C\u002Fspan\u003E\u003C\u002Fspan\u003E\u003C\u002Fspan\u003E or \u003Cspan class=\"katex\"\u003E\u003Cspan class=\"katex-mathml\"\u003E\u003Cmath xmlns=\"http:\u002F\u002Fwww.w3.org\u002F1998\u002FMath\u002FMathML\"\u003E\u003Csemantics\u003E\u003Cmrow\u003E\u003Cmi\u003EB\u003C\u002Fmi\u003E\u003C\u002Fmrow\u003E\u003Cannotation encoding=\"application\u002Fx-tex\"\u003EB\u003C\u002Fannotation\u003E\u003C\u002Fsemantics\u003E\u003C\u002Fmath\u003E\u003C\u002Fspan\u003E\u003Cspan class=\"katex-html\" aria-hidden=\"true\"\u003E\u003Cspan class=\"base\"\u003E\u003Cspan class=\"strut\" style=\"height:0.6833em;\"\u003E\u003C\u002Fspan\u003E\u003Cspan class=\"mord mathnormal\" style=\"margin-right:0.05017em;\"\u003EB\u003C\u002Fspan\u003E\u003C\u002Fspan\u003E\u003C\u002Fspan\u003E\u003C\u002Fspan\u003E in light of argument \u003Cspan class=\"katex\"\u003E\u003Cspan class=\"katex-mathml\"\u003E\u003Cmath xmlns=\"http:\u002F\u002Fwww.w3.org\u002F1998\u002FMath\u002FMathML\"\u003E\u003Csemantics\u003E\u003Cmrow\u003E\u003Cmi\u003ES\u003C\u002Fmi\u003E\u003C\u002Fmrow\u003E\u003Cannotation encoding=\"application\u002Fx-tex\"\u003ES\u003C\u002Fannotation\u003E\u003C\u002Fsemantics\u003E\u003C\u002Fmath\u003E\u003C\u002Fspan\u003E\u003Cspan class=\"katex-html\" aria-hidden=\"true\"\u003E\u003Cspan class=\"base\"\u003E\u003Cspan class=\"strut\" style=\"height:0.6833em;\"\u003E\u003C\u002Fspan\u003E\u003Cspan class=\"mord mathnormal\" style=\"margin-right:0.05764em;\"\u003ES\u003C\u002Fspan\u003E\u003C\u002Fspan\u003E\u003C\u002Fspan\u003E\u003C\u002Fspan\u003E?“).\u003C\u002Fp\u003E\n\u003C\u002Faside\u003E\n\n\u003Cp\u003EHuman biases로 인한 ML의 제한성을 피하기 위해 사람들을 대상으로 하는 것 대신 ML agent들을 활용하여 Human biases를 줄이려 하였다. (This is a variant of the “Wizard of Oz” technique from the human-computer interaction (HCI) community)\u003C\u002Fp\u003E\n\u003Cp\u003EML agent의 규칙(role)은 ML background를 가진 사람들이 설계하는 것이 아닌, 사회 과학자(social scientists)들이 세심하게 설계한다. 그리고 다양한 질문들은 각 분야의 사람들로 부터 구성된다.\u003C\u002Fp\u003E\n\u003Cp\u003E“We believe close collaborations between social scientists and ML researchers will be necessary to improve our understanding of the human side of AI alignment.”\u003C\u002Fp\u003E\n\u003Cp\u003E\u003Cem\u003E좋은 데이터와 바른 Metric이 모델을 만든다.\u003C\u002Fem\u003E\u003C\u002Fp\u003E\n\u003Ch2 id=\"ai-alignment\"\u003EAI alignment\u003Ca href=\"#ai-alignment\" class=\"anchor\"\u003E\u003Cspan class=\"visually-hidden\"\u003E#\u003C\u002Fspan\u003E\u003C\u002Fa\u003E\u003C\u002Fh2\u003E\u003Cp\u003E\u003Cstrong\u003EAI alignment\u003C\u002Fstrong\u003E (or value alignment) is the task of ensuring that \u003Cstrong\u003Eartificial intelligence systems reliably do what humans want\u003C\u002Fstrong\u003E.\u003C\u002Fp\u003E\n\u003Cp\u003E연구자들은 아래의 사항을 구분하고자 하였다.\u003C\u002Fp\u003E\n\u003Col\u003E\n\u003Cli\u003Etraining AI systems to identify actions that humans consider good \u003Cem\u003E(relatively personalized)\u003C\u002Fem\u003E\u003C\u002Fli\u003E\n\u003Cli\u003Etraining AI systems to identify actions that are “good” in some objective and universal sense\u003C\u002Fli\u003E\n\u003C\u002Fol\u003E\n\u003Cp\u003E다양한 개인적 특성을 가진 방대한 양의 데이터로부터 모델은 패턴을 찾아야 한다. 패턴은 사용자가 만족하는 결과이다.\u003C\u002Fp\u003E\n\u003Cp\u003E문제를 세분화 하게 되면,\u003C\u002Fp\u003E\n\u003Col\u003E\n\u003Cli\u003EHave a satisfactory definition of human values.\u003C\u002Fli\u003E\n\u003Cli\u003EGather data about human values, in a manner compatible with the definition.\u003C\u002Fli\u003E\n\u003Cli\u003EFind reliable ML algorithms that can learn and generalize from this data.\u003C\u002Fli\u003E\n\u003C\u002Fol\u003E\n\u003Ch3 id=\"learning-values-by-asking-humans-questions\"\u003E\u003Cstrong\u003ELearning values by asking humans questions\u003C\u002Fstrong\u003E\u003Ca href=\"#learning-values-by-asking-humans-questions\" class=\"anchor\"\u003E\u003Cspan class=\"visually-hidden\"\u003E#\u003C\u002Fspan\u003E\u003C\u002Fa\u003E\u003C\u002Fh3\u003E\u003Cp\u003EHuman values는 정의하기 어렵고 복잡하여 간단히 표현하기 어렵다. 단순히 선호나 행복, 만족을 의미하는 것이 아니다. 복잡한 사실 관계와 명확히 values로 풀어낼 수 없을 수도 있다.\u003C\u002Fp\u003E\n\u003Cp\u003EHuman values에 대한 판단이 인간의 직관으로 어려울 수 있다 \u003Cem\u003E(모호성).\u003C\u002Fem\u003E 이 경우에는 옳고 그름에 대한 QA 데이터 학습을 통해 ML 모델이 근사적으로 접근한다. 하지만, 상호적 대화와 관련된 데이터는 한정적이고, 책이나 인터넷을 통해 대화 내용을 찾을 수 있지만, 정형화 된것이 아니며, 규범적이지 않을 수도 있다. 여기서 패턴을 찾을 수 있지만, 어려운 것은 좋지 않음으로부터 좋음을 배워야 한다.\u003C\u002Fp\u003E\n\u003Ch3 id=\"definitions-of-alignment-reasoning-and-reflective-equilibrium\"\u003E\u003Cstrong\u003EDefinitions of alignment: reasoning and reflective equilibrium\u003C\u002Fstrong\u003E\u003Ca href=\"#definitions-of-alignment-reasoning-and-reflective-equilibrium\" class=\"anchor\"\u003E\u003Cspan class=\"visually-hidden\"\u003E#\u003C\u002Fspan\u003E\u003C\u002Fa\u003E\u003C\u002Fh3\u003E\u003Cp\u003E… to be continued\u003C\u002Fp\u003E\n\u003Cp\u003E\u003Cem\u003Eitalic\u003C\u002Fem\u003E으로 표현된 것은 사견입니다. (\u003Cem\u003Eitalic\u003C\u002Fem\u003E is a personal perspective)\u003C\u002Fp\u003E\n\u003Ch3 id=\"reference\"\u003E\u003Cstrong\u003EReference\u003C\u002Fstrong\u003E\u003Ca href=\"#reference\" class=\"anchor\"\u003E\u003Cspan class=\"visually-hidden\"\u003E#\u003C\u002Fspan\u003E\u003C\u002Fa\u003E\u003C\u002Fh3\u003E\u003Col\u003E\n\u003Cli\u003E\u003Ca href=\"https:\u002F\u002Fdistill.pub\u002F2019\u002Fsafety-needs-social-scientists\u002F#alignment\"\u003Ehttps:\u002F\u002Fdistill.pub\u002F2019\u002Fsafety-needs-social-scientists\u002F\u003C\u002Fa\u003E\u003C\u002Fli\u003E\n\u003C\u002Fol\u003E\n\u003Cblockquote\u003E\n\u003Cp\u003E저자들인, \u003Ca href=\"https:\u002F\u002Fnaml.us\u002F\"\u003EGeoffrey Irving\u003C\u002Fa\u003E, \u003Ca href=\"http:\u002F\u002Fwww.amandaaskell.com\u002F\"\u003EAmanda Askell\u003C\u002Fa\u003E, 두 사람 모두 2019년에 OpenAI에서 연구하였지만, 현재(2023년)는 DeepMind와 Anthropic에서 연구를 하고 있다.\u003C\u002Fp\u003E\n\u003C\u002Fblockquote\u003E\n\u003Chr\u003E\n\u003Caside class=\"chatgpt-base\"\u003E\u003Cdiv class=\"chatgpt-mark\"\u003EMark\u003C\u002Fdiv\u003E\u003Cdiv class=\"chatgpt-text\"\u003E\u003Cp\u003EWhat is AI safety in yours?\u003C\u002Fp\u003E\n\u003Cul\u003E\n\u003Cli\u003EAs an AI language model, I don’t have personal opinions or emotions. … (explanation)\u003C\u002Fli\u003E\n\u003C\u002Ful\u003E\n\u003C\u002Fdiv\u003E\u003C\u002Faside\u003E\u003Cp\u003E모델 자체가 방향성을 표현하지 않는다. 모델 자체는 일반성을 가지려고 한다.\u003C\u002Fp\u003E\n"],"uses":{"params":["path","slug"]}}]}
