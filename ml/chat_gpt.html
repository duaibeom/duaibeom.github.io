<!DOCTYPE html>
<html lang="en">
	<head>
		<meta charset="utf-8" />
		<link rel="icon" href="../favicon.png" />
		<meta name="viewport" content="width=device-width" />
		<meta http-equiv="content-security-policy" content="">
		<link href="../_app/immutable/assets/_layout.8634efe4.css" rel="stylesheet">
		<link href="../_app/immutable/assets/_page.8ebbd519.css" rel="stylesheet">
		<link rel="modulepreload" href="../_app/immutable/entry/start.515f0d26.js">
		<link rel="modulepreload" href="../_app/immutable/chunks/index.5621f243.js">
		<link rel="modulepreload" href="../_app/immutable/chunks/singletons.02becfe2.js">
		<link rel="modulepreload" href="../_app/immutable/entry/app.8b861ad3.js">
		<link rel="modulepreload" href="../_app/immutable/entry/_layout.svelte.f8856493.js">
		<link rel="modulepreload" href="../_app/immutable/entry/(posts)-_path_-_slug_-page.svelte.f5b1f45e.js">
	</head>
	<body data-sveltekit-preload-data="hover">
		<div style="display: contents">


<body><header><nav><div class="title"><a href="/">db&#39;Doodle</a></div>
		<div class="links"><ul><li><a href="/about">ABOUT</a></li>
				<li><a href="/blog">Blog</a></li>
				<li><a href="/ml">ML</a></li>
				<li><a href="/cs">CS</a></li>
				<li><a href="/tech">Tech</a></li></ul></div></nav></header>

	<div class="contents"><div class="post-title"><h1>Learn ChatGPT from ChatGPT</h1>
		</div>
	

	<div class="metadata"><div class="metadata-img"><svg data-name="Layer 1" xmlns="http://www.w3.org/2000/svg" width="110" height="80" viewBox="0 0 786.81995 572.25773" xmlns:xlink="http://www.w3.org/1999/xlink"><g fill="#f2f2f2"><circle cx="458.3" cy="74.2" r="26.7"></circle><path d="M665.4 497.2C705 467 724 416 712.2 367.7q-.4-1.8-1-3.6c-8-28.8-27.3-56-55.7-65.3-23.8-7.7-49.8-1.8-74.7-5-48.8-6-86.6-45.5-113.2-86.8s-47-87.6-82.4-121.7C327 29 232 17 159.7 53.6s-118.3 118-116.3 199 50 158.4 120 199.5c25.7 15 55.3 25.8 84.8 22 25.6-3.2 49-17 74.4-21 40-6.4 80 11.7 114.6 32.8s68.2 46.2 107.6 56c38.3 9.5 85.7-17.8 120.8-44.6z"></path></g><g fill="#3f3d56"><path d="M608.4 55.3l-2.6-1.7a380 380 0 0 0-80.3-38.9L519 105h-41.5V1.5l-8-1.5v105h-49.3C364 105 318 59 318 2.7h0l-8 1.8V105h-40l-6.2-86a381 381 0 0 0-81.9 43.5l-1.3 1L174 68v344.2h118.3l-2-29-11.5-159h231.6l-11.5 159-2 29h117V58.8q-2.6-1.8-5.2-3.5zM310.2 198h-33.4l-6.2-85.3h39.6zm159.4 0h-56v-1.7c0-1.6-.7-3.2-1.8-4.4s-2.7-1.8-4.4-1.8H383c-1.6 0-3.2.7-4.4 1.8s-1.8 2.7-1.8 4.4v1.7H318v-85.3h151.5zm8 0v-85.3h41l-6.2 85.3zM0 434.3a289 289 0 0 0 28.1 29l730.6 1a289 289 0 0 0 28.1-29z"></path><path d="M495.4 341.6v85.7c0 2.3 1.8 4 4 4h127c2.3 0 4-1.8 4-4v-85.7c0-2.3-1.8-4-4-4h-127c-2.3 0-4 1.8-4 4z"></path></g><path d="M498.4 342.7v83.6c0 1.2 1 2.2 2.2 2.2h125c1.2 0 2.2-1 2.2-2.2v-83.6c0-1.2-1-2.2-2.2-2.2h-125c-1.2 0-2.2 1-2.2 2.2z" fill="#6c63ff"></path><path d="M492.8 444c.5.6 1.2 1 2 1h136c.8 0 1.5-.3 2-1s.7-1.4.5-2l-2-10c-.2-.8-.8-1.5-1.6-1.8-.3-.1-.6-.2-1-.2H496.8c-.3 0-.6.1-1 .2-.8.3-1.4 1-1.6 1.8l-2 10c-.2.7 0 1.5.5 2z" fill="#2f2e41"></path><g fill="#3f3d56"><rect x="830" y="595.6" width="4.2" height="2.5" rx=".5" transform="matrix(-1 0 0 -1 1457.67 1029.82)"></rect><rect x="821.7" y="595.6" width="4.2" height="2.5" rx=".5" transform="matrix(-1 0 0 -1 1440.91 1029.82)"></rect><rect x="813.3" y="595.6" width="4.2" height="2.5" rx=".5" transform="matrix(-1 0 0 -1 1424.16 1029.82)"></rect><rect x="804.9" y="595.6" width="4.2" height="2.5" rx=".5" transform="matrix(-1 0 0 -1 1407.4 1029.82)"></rect><rect x="796.5" y="595.6" width="4.2" height="2.5" rx=".5" transform="matrix(-1 0 0 -1 1390.65 1029.82)"></rect><rect x="788.1" y="595.6" width="4.2" height="2.5" rx=".5" transform="matrix(-1 0 0 -1 1373.9 1029.82)"></rect><rect x="779.8" y="595.6" width="4.2" height="2.5" rx=".5" transform="matrix(-1 0 0 -1 1357.14 1029.82)"></rect><rect x="771.4" y="595.6" width="4.2" height="2.5" rx=".5" transform="matrix(-1 0 0 -1 1340.39 1029.82)"></rect><rect x="763" y="595.6" width="4.2" height="2.5" rx=".5" transform="matrix(-1 0 0 -1 1323.63 1029.82)"></rect><rect x="754.6" y="595.6" width="4.2" height="2.5" rx=".5" transform="matrix(-1 0 0 -1 1306.88 1029.82)"></rect><rect x="746.3" y="595.6" width="4.2" height="2.5" rx=".5" transform="matrix(-1 0 0 -1 1290.13 1029.82)"></rect><rect x="737.9" y="595.6" width="4.2" height="2.5" rx=".5" transform="matrix(-1 0 0 -1 1273.37 1029.82)"></rect><rect x="729.5" y="595.6" width="4.2" height="2.5" rx=".5" transform="matrix(-1 0 0 -1 1256.62 1029.82)"></rect><rect x="721.1" y="595.6" width="4.2" height="2.5" rx=".5" transform="matrix(-1 0 0 -1 1239.86 1029.82)"></rect><rect x="712.8" y="595.6" width="4.2" height="2.5" rx=".5" transform="matrix(-1 0 0 -1 1223.11 1029.82)"></rect><rect x="704.4" y="595.6" width="4.2" height="2.5" rx=".5" transform="matrix(-1 0 0 -1 1206.36 1029.82)"></rect><rect x="830.1" y="599.8" width="4.2" height="2.5" rx=".5" transform="matrix(-1 0 0 -1 1457.86 1038.2)"></rect><rect x="821.8" y="599.8" width="4.2" height="2.5" rx=".5" transform="matrix(-1 0 0 -1 1441.11 1038.2)"></rect><rect x="813.4" y="599.8" width="4.2" height="2.5" rx=".5" transform="matrix(-1 0 0 -1 1424.36 1038.2)"></rect><rect x="805" y="599.8" width="4.2" height="2.5" rx=".5" transform="matrix(-1 0 0 -1 1407.6 1038.2)"></rect><rect x="796.6" y="599.8" width="4.2" height="2.5" rx=".5" transform="matrix(-1 0 0 -1 1390.85 1038.2)"></rect><rect x="788.2" y="599.8" width="4.2" height="2.5" rx=".5" transform="matrix(-1 0 0 -1 1374.09 1038.2)"></rect><rect x="779.9" y="599.8" width="4.2" height="2.5" rx=".5" transform="matrix(-1 0 0 -1 1357.34 1038.2)"></rect><rect x="771.5" y="599.8" width="4.2" height="2.5" rx=".5" transform="matrix(-1 0 0 -1 1340.59 1038.2)"></rect><rect x="763.1" y="599.8" width="4.2" height="2.5" rx=".5" transform="matrix(-1 0 0 -1 1323.83 1038.2)"></rect><rect x="754.7" y="599.8" width="4.2" height="2.5" rx=".5" transform="matrix(-1 0 0 -1 1307.08 1038.2)"></rect><rect x="746.4" y="599.8" width="4.2" height="2.5" rx=".5" transform="matrix(-1 0 0 -1 1290.32 1038.2)"></rect><rect x="738" y="599.8" width="4.2" height="2.5" rx=".5" transform="matrix(-1 0 0 -1 1273.57 1038.2)"></rect><rect x="729.6" y="599.8" width="4.2" height="2.5" rx=".5" transform="matrix(-1 0 0 -1 1256.82 1038.2)"></rect><rect x="721.2" y="599.8" width="4.2" height="2.5" rx=".5" transform="matrix(-1 0 0 -1 1240.06 1038.2)"></rect><rect x="712.9" y="599.8" width="4.2" height="2.5" rx=".5" transform="matrix(-1 0 0 -1 1223.31 1038.2)"></rect><rect x="704.5" y="599.8" width="4.2" height="2.5" rx=".5" transform="matrix(-1 0 0 -1 1206.55 1038.2)"></rect><rect x="760.6" y="604.8" width="33.5" height="2.5" rx=".5" transform="matrix(-1 0 0 -1 1348.13 1048.25)"></rect></g><g fill="#fff"><rect x="515.6" y="358.7" width="6" height="3.1" rx="1.6"></rect><rect x="548.2" y="358.7" width="6" height="3.1" rx="1.6"></rect><rect x="557.4" y="358.7" width="6" height="3.1" rx="1.6"></rect><rect x="524.5" y="358.5" width="20.8" height="3.1" rx="1.6"></rect><rect x="567.8" y="358.5" width="20.8" height="3.1" rx="1.6"></rect><rect x="524.3" y="365.8" width="6" height="3.1" rx="1.6"></rect><rect x="556.8" y="365.8" width="6" height="3.1" rx="1.6"></rect><rect x="566" y="365.8" width="6" height="3.1" rx="1.6"></rect><rect x="533.2" y="365.5" width="20.8" height="3.1" rx="1.6"></rect><rect x="576.5" y="365.5" width="20.8" height="3.1" rx="1.6"></rect><rect x="533" y="372.8" width="6" height="3.1" rx="1.6"></rect><rect x="565.5" y="372.8" width="6" height="3.1" rx="1.6"></rect><rect x="574.7" y="372.8" width="6" height="3.1" rx="1.6"></rect><rect x="541.8" y="372.6" width="20.8" height="3.1" rx="1.6"></rect><rect x="585.2" y="372.6" width="20.8" height="3.1" rx="1.6"></rect><rect x="541.6" y="379.9" width="6" height="3.1" rx="1.6"></rect><rect x="574.2" y="379.9" width="6" height="3.1" rx="1.6"></rect><rect x="583.4" y="379.9" width="6" height="3.1" rx="1.6"></rect><rect x="550.5" y="379.6" width="20.8" height="3.1" rx="1.6"></rect><rect x="548.2" y="407.9" width="6" height="3.1" rx="1.6"></rect><rect x="557.4" y="407.9" width="6" height="3.1" rx="1.6"></rect><rect x="567.8" y="408.2" width="20.8" height="3.1" rx="1.6"></rect><rect x="515.6" y="407.9" width="6" height="3.1" rx="1.6"></rect><rect x="524.5" y="408.2" width="20.8" height="3.1" rx="1.6"></rect><rect x="524.3" y="400.9" width="6" height="3.1" rx="1.6"></rect><rect x="556.8" y="400.9" width="6" height="3.1" rx="1.6"></rect><rect x="566" y="400.9" width="6" height="3.1" rx="1.6"></rect><rect x="533.2" y="401.1" width="20.8" height="3.1" rx="1.6"></rect><rect x="533" y="393.8" width="6" height="3.1" rx="1.6"></rect><rect x="565.5" y="393.8" width="6" height="3.1" rx="1.6"></rect><rect x="574.7" y="393.8" width="6" height="3.1" rx="1.6"></rect><rect x="541.8" y="394.1" width="20.8" height="3.1" rx="1.6"></rect><rect x="541.6" y="386.8" width="6" height="3.1" rx="1.6"></rect><rect x="574.2" y="386.8" width="6" height="3.1" rx="1.6"></rect><rect x="583.4" y="386.8" width="6" height="3.1" rx="1.6"></rect><rect x="550.5" y="387" width="20.8" height="3.1" rx="1.6"></rect></g><path d="M505 490.5l-13.3-21 42-33.4 17.3-19.2c4.6-5 11.5-7.3 18.2-6s12 6.3 14.2 12.7h0c3.2 9.8-2 20.4-11.6 24l-27.3 10z" fill="#ffb6b6"></path><path d="M191.7 337.5V440h72V337.5c0-1.5-1-3-2.4-3.3-.3-.1-.7-.2-1-.2h-65c-1 0-1.8.4-2.5 1s-1 1.5-1 2.4zm28 35.2c0-4.2 3.5-7.6 7.7-7.6s7.6 3.4 7.7 7.6v12c0 4.2-3.4 7.6-7.7 7.6s-7.6-3.4-7.7-7.6z" fill="#2f2e41"></path><path d="M191.5 436.8v10c0 1 1 2 2 2H262c1 0 2-1 2-2v-10zM78.7 183v187.3a9 9 0 0 0 9 9h277.5a9 9 0 0 0 9-9V183a9 9 0 0 0-9-9H87.7a9 9 0 0 0-9 9z" fill="#3f3d56"></path><path d="M85.2 185.3V368c0 2.7 2.2 4.8 4.8 4.8h273c2.7 0 4.8-2.2 4.8-4.8V185.3c0-2.7-2.2-4.8-4.8-4.8H90c-2.7 0-4.8 2.2-4.8 4.8z" fill="#fff"></path><path d="M135.8 448c.6.7 1.4 1 2.3 1h162.3a3 3 0 0 0 2.9-3.6l-2.5-12a3 3 0 0 0-1.9-2.2c-.3-.1-.7-.2-1-.2H140.6c-.4 0-.7.1-1 .2a3 3 0 0 0-1.9 2.2l-2.5 12a3 3 0 0 0 .6 2.5z" fill="#2f2e41"></path><g fill="#3f3d56"><path d="M354 205.6H98.7c-.6 0-1-.5-1-1s.4-1 1-1H354c.6 0 1 .5 1 1s-.4 1-1 1z"></path><ellipse cx="116.1" cy="192.3" rx="6" ry="6.1"></ellipse><ellipse cx="136.6" cy="192.3" rx="6" ry="6.1"></ellipse><ellipse cx="157.2" cy="192.3" rx="6" ry="6.1"></ellipse><use xlink:href="#B"></use><use xlink:href="#B" y="4.2"></use><use xlink:href="#B" y="8.2"></use></g><path d="M693.6 441c1 2.6 3.4 4.4 6.2 4.3l26.5-.7c2.8-.1 5.2-2 6-4.7l3.7-40c1.3.6 2.8 1 4.2 1 5.3-.1 9.5-4.6 9.4-10s-4.6-9.5-10-9.4c-.6 0-1.2.1-1.7.2-1.3-1.4-3-2-5-2l-40.8 1c-.3 0-.7.1-1 .1-1.8.3-3.4 1.4-4.3 3s-1 3.5-.6 5.2zm43.2-43.8l2.7-9.6c.3-1 .3-2.3 0-3.4.1 0 .2-.1.4-.1 3.8-.1 7 3 7 6.7s-3 7-6.7 7c-1.2 0-2.4-.2-3.4-.8z" fill="#2f2e41"></path><path d="M691.4 380.8c1 5 10.6 8.5 22.4 7.8 10.8-.5 19.6-4.3 21.2-8.8a6 6 0 0 0-1.8-.2l-40.8 1c-.3 0-.7.1-1 .1z" fill="#3f3d56"></path><g fill="#6c63ff"><path d="M716 419c.1 0 .1 0 .2-.1l5.8-3.8c.1-.1.2-.2.2-.4s-.1-.3-.2-.4l-6-4c-.1-.1-.3-.1-.5 0s-.3.2-.3.4.1.3.2.4l5.3 3.5-5 3.3c-.2.1-.3.4-.2.6s.3.3.6.3zm-9.2.5c.2-.1.3-.2.4-.4s-.1-.4-.2-.5l-5.3-3 5-3.8c.1-.1.2-.3.2-.5s-.1-.3-.3-.4-.4 0-.5.1l-5.7 4.3c-.1.1-.2.3-.2.4s.1.3.3.4l6 3.4c.1.1.2.1.4.1zm8.5 3s.1 0 .1-.1c.1-.1.2-.2.2-.3s0-.3-.1-.4l-8.2-13.4c-.1-.2-.5-.3-.7-.2s-.3.5-.2.7l8.2 13.4c.1.2.3.3.5.2z"></path><rect x="209.4" y="260.8" width="50.7" height="10.8" rx="3.3"></rect></g><g fill="#e6e6e6"><rect x="183.6" y="282.5" width="102.2" height="10.8" rx="3.3"></rect><rect x="183.6" y="304.2" width="102.2" height="10.8" rx="3.3"></rect></g><g fill="#3f3d56"><path d="M290.7 376.8l.2.7h0l6.5 19.8 7.5 23 14 43 .1 6.7h0l1 53.7-3 7.3 3.3 12s-1.5-18-9.6-7.7c-4.6 6-10 12-14.3 17.6q9.6 4 19.5 7l4.3 1.3q.5.1 1 .3a267 267 0 0 0 67.4 10.8l3.5.1h1.2 3.8q4 0 7.7-.1a267 267 0 0 0 56.1-7.6l-1-26c-.2-4.6-5.4-9.7-5.7-14.5-.2-3.7 4.4-7 4-10.8-1.6-22.8-3.5-14-5-30.2q-.2-2.4-.4-4.6l-1.6-17 6-38.7 9.6-60.7-.7-1.2-.8-.4-50.8-25.2-2.8-7a11 11 0 0 0-10.1-6.9l-33.5-.1c-3.5 0-6.8 1.7-9 4.5l-9 12.6z"></path><path d="M326.8 453.7l-7.6 16.2-5.2 11-9 46.6-4.5 4.7-3.8-16.8-40 9c-1.3-7.3-.4.2-1.2-7.8l.7-.7c.6-.6 1.2-1.2 1.2-1.7-.5-27.6 1-74.5 12.3-103a60 60 0 0 1 7-13.1l.7-1 13.3-19.8h0l.1-.1 32.4-17.2 1.4 39 1 28zm117 4.6l9.5 20.3 3.3 7 9 46.6 4.4 4.7 3.8-16.8 1.8-.4L508 513l9.5 30a18 18 0 0 0-3.3-22.5c-.6-.6-1.2-1.2-1.2-1.7.5-32.4-1.4-91.7-19.4-116-5.7-7.7-9-15.4-14-20.8l-12-19.8-.7-1.2-.8-.4z"></path></g><circle cx="386.4" cy="267.2" r="44.6" fill="#ffb6b6"></circle><path d="M446.6 236c-.7-.7-1.7-1.2-2.7-1.2l.7-2c.4-1.2.2-2.5-.6-3.5s-2-1.4-3.4-1.2l-2.4.5.2-1.6c.2-1.2-.3-2.5-1.3-3.3s-2.3-1-3.5-.6c-1 .4-2.3.3-3.2-.2-1-.5-1.7-1.5-2-2.6l-1-4-.1-.2c-4-7-12-12-21.8-13.8-8.7-1.6-17.6-.8-26 0-3.4.3-7.2.7-10.4 2.6-2.7 1.7-5 5-4.5 8.4-8.5-2.6-17.5 2.6-22 9-5.3 7.8-6.2 17.5-6.3 25-.4 18 3.3 32.7 11 43.7.6.8.7 2.5 1.8 3v-.4c1.2.6 2.5 1.6 2 2.7-1.4 3 7.6 10 14 12a88 88 0 0 0 37.6 2.3l.4-2.6c4-.5 6.6-1.5 7.4-3l3.5-3.2h0v-.1c5-4.7 6-7.3 6.5-11.4.5-4-.4-8-1.3-11.6 18.7 3-7.4-20 10-24.4.2-.1.4-.1.6-.1l1.5-.4c2.4-.6 4.6-1.6 6.7-3 5-3 6.5-7 9-11.4.7-1.3.6-3-.4-4zM544 461.4v7.2q0 .6 0 1.3l-.5 15.4v1l-1.5 29c-1.4 24.7-4 3.4-6.3 12l-.4 1.5a28 28 0 0 1-1.9 6.3l-4 2.3a281 281 0 0 1-11.5 6.1l-6.6 3.2-1 .5a271 271 0 0 1-34.7 13.3 241 241 0 0 1-7 2l-7.4 2a267 267 0 0 1-56.1 7.6l-7.7.1h-3.8-1.2l-3.5-.1a270 270 0 0 1-67.4-10.8l-1-.3-4.3-1.3q-10-3-19.5-7-7.3-3-14.5-6.3s-.1 0-.1-.1l-3-1.4c-.1-.1-.3-.1-.4-.2q-5.6-2.7-11-5.7c-3-7-7.4-8.4-10-14.6a26 26 0 0 1-1.7-5.7v-.1c.3 3.7-1.2-6.6 0 0v-.4-1.4c-3.4-33.5-3.2-71.8-4.7-103.4q-.2-3-.3-6l-.1-1.8.2-.5a1 1 0 0 1 .1-.1l.1-.2v-.1s0-.1.1-.1l.3-.4.1-.2c0-.1.1-.1.1-.1l.1-.1v-.1s0-.1.1-.1c.1-.1.2-.2.3-.2l1-1 .4-.3c1-.6 2-1 3.2-1.5.4-.1.8-.3 1.2-.4l.4-.1h.7c1-.3 2.4-.6 3.7-1l.5-.1.7-.1 1-.2c3-.5 6.3-.8 10-1q.5 0 1-.1h1.2 1 1l3-.1h9.5l4.8.1h.3l4.3.2c1 0 2 .1 3 .2l3 .2h2.3 2l1 .1 1.5.1 3.3.3 3.4.3 3.4.3h.3l3 .3.7.1 3 .3h1l2.4.3 3.2.4 2.4.3 4 .5 1.5.2L357 403a869 869 0 0 1 17.4 2.6q8.8 1.4 17.7 3l4.5.8q1 .2 2 .4l3.5.6 3.5.7 4 .8 27 5.7 4.3 1q4.3 1 8.6 2l2.3.6 5.7 1.5h.3a224 224 0 0 1 4.1 1q4.8 1.3 9.5 2.5 3 1 6 1.7l8.8 2.6 2 .6 6.2 2 4.7 1.6q2.3.8 4.5 1.6l2.8 1 4 1.5 1.2.5.7.3 1.4.6 1.4.6 1.4.6 1.3.6 1 .5 2 1 1 .5.8.4.3.2c.3.1.5.3.8.4.6.3 1 .6 1.7.8l2.2 1 2 1h.3l.5.3 1.5 1 2.7 1.8.6.4 1.8 1.3c.2.1.4.3.6.4.1.1.3.3.5.4l1.4 1.3.4.4c.1 0 .1.1.2.2l.6.6s0 .1.1.1l.7.8c.1.1.2.3.3.4l.3.5.3.4.5 1 .3.8c.1.3.1.5.2.8z" fill="#2f2e41"></path><path d="M544 461.4v7.2 1.3l-.5 15.4v1l-1.5 29c-1.4 24.7-4 3.4-6.3 12L513 514.3q-2.2-1.2-4.4-2.5c-16-9-34-18.4-52.8-27.7l-2.2-1L326 427.4l-21-7.2c-14-4.4-25.8-7.5-35-9-9.6-1.4-16.2-1-19 2q-.2-3-.3-6-.1-1-.1-1.8c.1-.2.1-.3.2-.5 0 0 0 0 0-.1a1 1 0 0 1 .1-.1l.1-.2c0-.1.1-.1.1-.2l.3-.4.3-.3c0 0 .1-.1.1-.1l.1-.1c0 0 0-.1.1-.1.1-.1.2-.2.3-.2l1-1 .4-.3c1-.6 2-1 3.2-1.5.4-.1.8-.3 1.2-.4l.4-.1.7-.2c1-.3 2.4-.6 3.7-1l1.2-.2 1-.2c3-.5 6.3-.8 10-1q.5 0 1-.1h1.2c.4 0 .7 0 1 0 .4 0 .7 0 1 0l3-.1h9.5l4.8.1h.3l4.3.2c1 0 2 .1 3 .2l3 .2h2.3l2 .1 2.4.2 3.3.3 3.4.3 3.4.3h.3l3 .3q8.7 1 18 2 5.5.7 11.2 1.5l17.4 2.6q8.8 1.4 17.7 3l4.5.8q2.8.5 5.5 1l3.5.7 4 .8 27 5.7 4.3 1q4.3 1 8.6 2l2.3.6q3 .7 5.7 1.4h0 .3a409 409 0 0 1 4.1 1.1q4.8 1.3 9.5 2.5l6 1.7 8.8 2.6 2 .6q3 1 6.2 2l4.7 1.6q2.3.8 4.5 1.6l2.8 1 4 1.5 1.2.5 2 1 1.4.6 1.3.6 1.3.6 1 .5 2 1 1 .5.8.4.3.2a115 115 0 0 1 2.5 1.2l2.2 1 2.4 1.3.5.3 1.5 1 2.7 1.8 2.4 1.7 1 .8 1.4 1.3c.1.1.3.3.4.4.1 0 .1.1.2.2l.6.7.7.8c.1.1.2.3.3.4l.3.5.3.4c.2.4.4.7.5 1 .1.3.2.5.3.8.1.3.1.5.2.8z" opacity=".2"></path><defs><path id="B" d="M341.6 187.8H327c-.6 0-1 .5-1 1s.5 1 1 1h14.6c.6 0 1-.5 1-1s-.5-1-1-1z"></path></defs></svg></div>
		<div class="metadata-text"><p style="display: flex; margin: 0; align-self: end;"><span style="font-weight: 600;">By Duaibeom</span>
				<span style="color: #57606a; margin-left: auto;">Feb. 3, 2023</span></p>
			<ul class="tag" style="justify-self: end; align-self: start;"><li>GPT</li><li>OpenAI</li></ul></div></div>
	

	<div class="base-grid"><div class="grid-toc"><div class="toc"><!-- HTML_TAG_START --><h4>Contents</h4><p class="toc-h3"><a href="#understand-chatgpt-technology">Understand ChatGPT Technology</a></p><p class="toc-h3"><a href="#attention-is-all-you-need">Attention is All you Need</a></p><p class="toc-h3"><a href="#gpt">GPT</a></p><p class="toc-h3"><a href="#gpt-vs-transformer">GPT vs. Transformer</a></p><p class="toc-h3"><a href="#text-and-code-embeddings-by-contrastive-pre-training">Text and Code Embeddings by Contrastive Pre-Training</a></p><p class="toc-h3"><a href="#autoregressive-model">Autoregressive model</a></p><p class="toc-h3"><a href="#zero-shot-learning">Zero-Shot learning</a></p><p class="toc-h3"><a href="#min-gpt">min GPT</a></p><p class="toc-h3"><a href="#pros-and-cons">Pros and Cons</a></p><!-- HTML_TAG_END --></div></div>
		

		<div class="grid-article"><!-- HTML_TAG_START --><h3 id="understand-chatgpt-technology">Understand ChatGPT Technology<a href="#understand-chatgpt-technology" class="anchor"><span class="visually-hidden">#</span></a></h3><p>ChatGPT is a conversational AI model developed by OpenAI. It’s based on the Transformer architecture and is trained on a large corpus of text data to generate human-like responses to text-based inputs. To understand ChatGPT, you should know the following basics:</p>
<ol>
<li>Natural Language Processing (NLP): ChatGPT uses NLP techniques to understand and generate human language.</li>
<li>Machine learning: ChatGPT is a machine learning model that uses supervised learning to generate text responses.</li>
<li>Transformer architecture: This is a neural network architecture used in NLP tasks that was introduced in the 2017 paper “Attention is All You Need”.</li>
<li>Pre-training: ChatGPT is a pre-trained model that was fine-tuned on a large corpus of text data to generate text responses.</li>
<li>Fine-tuning: This is the process of training a pre-trained model on a smaller, specific task-specific dataset to adapt it to a particular use case.</li>
<li>Generative model: ChatGPT is a generative model, which means it generates text rather than simply classifying or translating it.</li>
<li>Language generation: ChatGPT uses probabilistic language generation techniques to generate text responses that are contextually relevant to the input prompt.</li>
</ol>
<h3 id="attention-is-all-you-need">Attention is All you Need<a href="#attention-is-all-you-need" class="anchor"><span class="visually-hidden">#</span></a></h3><p>The authors argue that attention mechanisms are sufficient for building deep learning models for NLP tasks, such as machine translation, and that these models can be trained effectively in an end-to-end manner.</p>
<p><strong>Self-attention mechanisms</strong> allow the model to selectively focus on different parts of the input sequence. This allows the model to process input sequences in parallel, which makes it faster and more parallelizable than RNNs.</p>
<p>The Transformer architecture also introduced the concept of <strong>multi-head attention</strong>, which allows the model to attend to different parts of the input sequence in multiple ways, and <strong>the position encoding mechanism</strong>, which encodes the relative position of words in a sentence.</p>
<h3 id="gpt">GPT<a href="#gpt" class="anchor"><span class="visually-hidden">#</span></a></h3><p>GPT stands for <strong>Generative Pretrained Transformer</strong>, which is a language generation model developed by OpenAI.</p>
<p>GPT uses a large corpus of text data to pre-train a deep neural network on the task of <strong>predicting the next word in a sentence</strong>. The pre-training allows the model <strong>to learn general language patterns and relationships</strong>, so that it can generate text that is similar to the training data.</p>
<h3 id="gpt-vs-transformer">GPT vs. Transformer<a href="#gpt-vs-transformer" class="anchor"><span class="visually-hidden">#</span></a></h3><ul>
<li>The Transformer architecture is a type of neural network that can be used for various NLP tasks.</li>
<li>GPT is a specific pre-trained language generation model based on the Transformer architecture.</li>
</ul>
<div class="code-block python"><pre class='language-python'><code><span class="token comment"># Simple implementation of Transformer</span>
<span class="token keyword">import</span> torch
<span class="token keyword">import</span> torch<span class="token punctuation">.</span>nn <span class="token keyword">as</span> nn
<span class="token keyword">import</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>functional <span class="token keyword">as</span> F

<span class="token keyword">class</span> <span class="token class-name">Transformer</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> d_model<span class="token punctuation">,</span> nhead<span class="token punctuation">,</span> num_encoder_layers<span class="token punctuation">,</span> num_decoder_layers<span class="token punctuation">,</span> dim_feedforward<span class="token punctuation">,</span> dropout<span class="token operator">=</span><span class="token number">0.1</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token builtin">super</span><span class="token punctuation">(</span>Transformer<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>

        self<span class="token punctuation">.</span>encoder_layer <span class="token operator">=</span> nn<span class="token punctuation">.</span>TransformerEncoderLayer<span class="token punctuation">(</span>d_model<span class="token punctuation">,</span> nhead<span class="token punctuation">,</span> dim_feedforward<span class="token punctuation">,</span> dropout<span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>transformer_encoder <span class="token operator">=</span> nn<span class="token punctuation">.</span>TransformerEncoder<span class="token punctuation">(</span>self<span class="token punctuation">.</span>encoder_layer<span class="token punctuation">,</span> num_encoder_layers<span class="token punctuation">)</span>

        self<span class="token punctuation">.</span>decoder_layer <span class="token operator">=</span> nn<span class="token punctuation">.</span>TransformerDecoderLayer<span class="token punctuation">(</span>d_model<span class="token punctuation">,</span> nhead<span class="token punctuation">,</span> dim_feedforward<span class="token punctuation">,</span> dropout<span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>transformer_decoder <span class="token operator">=</span> nn<span class="token punctuation">.</span>TransformerDecoder<span class="token punctuation">(</span>self<span class="token punctuation">.</span>decoder_layer<span class="token punctuation">,</span> num_decoder_layers<span class="token punctuation">)</span>

    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> src<span class="token punctuation">,</span> tgt<span class="token punctuation">,</span> src_mask<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">,</span> tgt_mask<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">,</span> memory_mask<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">,</span> src_key_padding_mask<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">,</span> tgt_key_padding_mask<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">,</span> memory_key_padding_mask<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        memory <span class="token operator">=</span> self<span class="token punctuation">.</span>transformer_encoder<span class="token punctuation">(</span>src<span class="token punctuation">,</span> src_mask<span class="token punctuation">)</span>
        output <span class="token operator">=</span> self<span class="token punctuation">.</span>transformer_decoder<span class="token punctuation">(</span>tgt<span class="token punctuation">,</span> memory<span class="token punctuation">,</span> tgt_mask<span class="token punctuation">,</span> memory_mask<span class="token punctuation">)</span>
        <span class="token keyword">return</span> output</code></pre></div><div class="code-block python"><pre class='language-python'><code><span class="token comment"># Simple implementation of GPT-1</span>
<span class="token keyword">import</span> torch
<span class="token keyword">import</span> torch<span class="token punctuation">.</span>nn <span class="token keyword">as</span> nn
<span class="token keyword">import</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>functional <span class="token keyword">as</span> F

<span class="token keyword">class</span> <span class="token class-name">GPT1</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> vocab_size<span class="token punctuation">,</span> d_model<span class="token punctuation">,</span> nhead<span class="token punctuation">,</span> num_layers<span class="token punctuation">,</span> dim_feedforward<span class="token punctuation">,</span> dropout<span class="token operator">=</span><span class="token number">0.1</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token builtin">super</span><span class="token punctuation">(</span>GPT1<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>

        self<span class="token punctuation">.</span>embedding <span class="token operator">=</span> nn<span class="token punctuation">.</span>Embedding<span class="token punctuation">(</span>vocab_size<span class="token punctuation">,</span> d_model<span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>transformer <span class="token operator">=</span> nn<span class="token punctuation">.</span>Transformer<span class="token punctuation">(</span>d_model<span class="token punctuation">,</span> nhead<span class="token punctuation">,</span> num_layers<span class="token punctuation">,</span> dim_feedforward<span class="token punctuation">,</span> dropout<span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>fc <span class="token operator">=</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span>d_model<span class="token punctuation">,</span> vocab_size<span class="token punctuation">)</span>

    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">)</span><span class="token punctuation">:</span>
        x <span class="token operator">=</span> self<span class="token punctuation">.</span>embedding<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
        x <span class="token operator">=</span> self<span class="token punctuation">.</span>transformer<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
        x <span class="token operator">=</span> self<span class="token punctuation">.</span>fc<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
        <span class="token keyword">return</span> x</code></pre></div><h3 id="text-and-code-embeddings-by-contrastive-pre-training">Text and Code Embeddings by Contrastive Pre-Training<a href="#text-and-code-embeddings-by-contrastive-pre-training" class="anchor"><span class="visually-hidden">#</span></a></h3><p>Paper: </p>
<p>The paper proposes a novel pre-training method for learning text and code embeddings. The main idea behind the method is to use a contrastive loss function to pre-train the embeddings in an unsupervised manner.</p>
<p>The loss function used for this prediction task is a contrastive loss function that encourages the embeddings of similar tokens (e.g., tokens with similar meanings) to be close together in the embedding space, while encouraging the embeddings of dissimilar tokens to be far apart.</p>
<p>Zero-shot learning is a machine learning approach where a model is trained to recognize and classify new, unseen classes without any additional training data. </p>
<h3 id="autoregressive-model">Autoregressive model<a href="#autoregressive-model" class="anchor"><span class="visually-hidden">#</span></a></h3><p>An autoregressive model is a type of statistical model that is used for time series forecasting and sequence generation tasks. In an autoregressive model, the current output or prediction is a function of previous inputs or outputs in the sequence.</p>
<p>The most common form of an autoregressive model is the Autoregressive Integrated Moving Average (ARIMA) model, which is used in time series analysis to model the dependencies between observations over time. ARIMA models can be used to perform various tasks, such as prediction of future values, identifying trends and patterns in time series data, and modeling the impact of past events on future outcomes.</p>
<p>In the field of machine learning and artificial neural networks, autoregressive models are used for sequence generation tasks, such as text generation and music composition.</p>
<h3 id="zero-shot-learning">Zero-Shot learning<a href="#zero-shot-learning" class="anchor"><span class="visually-hidden">#</span></a></h3><p>The goal of zero-shot learning is to learn a model that can generalize to new classes based on prior knowledge or information about the relationships between classes, without the need for additional labeled examples of those classes.</p>
<p>In zero-shot learning, a model is typically trained on a set of source classes and <strong>a semantic representation</strong> of each class is obtained.</p>
<p>Zero-shot learning is a challenging problem in machine learning, and it is particularly useful for applications where it is not feasible to collect labeled data for every class. For example, in computer vision, zero-shot learning can be used to recognize and classify new species of animals or plants without the need for labeled images of those species.</p>
<p>e.g. <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mtext>zebras</mtext><mo>=</mo><mtext>striped</mtext><mo>+</mo><mtext>horses</mtext></mrow><annotation encoding="application/x-tex">\text{zebras} = \text{striped} + \text{horses}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6944em;"></span><span class="mord text"><span class="mord">zebras</span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.8889em;vertical-align:-0.1944em;"></span><span class="mord text"><span class="mord">striped</span></span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.6944em;"></span><span class="mord text"><span class="mord">horses</span></span></span></span></span></p>
<hr>
<p>Not from ChatGPT</p>
<h3 id="min-gpt">min GPT<a href="#min-gpt" class="anchor"><span class="visually-hidden">#</span></a></h3><p><a href="https://github.com/karpathy/minGPT/blob/master/mingpt/model.py">https://github.com/karpathy/minGPT/blob/master/mingpt/model.py</a></p>
<h3 id="pros-and-cons">Pros and Cons<a href="#pros-and-cons" class="anchor"><span class="visually-hidden">#</span></a></h3><ul>
<li><p>too generalized &lt;–&gt; more proper answers for everyone</p>
</li>
<li></li>
</ul>
<!-- HTML_TAG_END --></div>
		</div>

	<div class="controls svelte-1wai065"><ul class="svelte-1wai065"><li class="prev svelte-1wai065"><span class="svelte-1wai065">previous</span>
			<a href="/ml/vision_transformer">Vision Transformer</a></li>

		<li class="next svelte-1wai065"><span class="svelte-1wai065">next</span>
			<a href="/ml/pytorch">PyTorch</a></li></ul>
</div>

	<script src="https://giscus.app/client.js" data-repo="duaibeom/duaibeom.github.io" data-repo-id="R_kgDOGXam8A" data-category="General" data-category-id="DIC_kwDOGXam8M4COJSN" data-mapping="pathname" data-reactions-enabled="1" data-emit-metadata="0" data-input-position="bottom" data-theme="light" data-lang="en" crossorigin="anonymous" async></script></div>

	<footer><ul><li style="color: white;">© 2019 - 2023 Duaibeom Blog.</li>
		<li style="color: grey;">Powered by Svelte-kit(static) &amp; GitHub Pages</li></ul>
	<ul style="margin-left: auto;"><li><a href="/" style="color: #959da5;"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 19 19" class="d-block" height="20"><path d="M3.94 2A2 2 0 1 1 2 0a2 2 0 0 1 1.94 2zM4 5.48H0V18h4zm6.32 0H6.34V18h3.94v-6.57c0-3.66 4.77-4 4.77 0V18H19v-7.93c0-6.17-7.06-5.94-8.72-2.91z" fill="currentColor"></path></svg></a></li>
		<li><a href="https://github.com/duaibeom" style="color: #959da5;"><svg height="20" viewBox="0 0 16 16" version="1.1" aria-hidden="true"><path fill-rule="evenodd" d="M8 0C3.58 0 0 3.58 0 8c0 3.54 2.29 6.53 5.47 7.59.4.07.55-.17.55-.38 0-.19-.01-.82-.01-1.49-2.01.37-2.53-.49-2.69-.94-.09-.23-.48-.94-.82-1.13-.28-.15-.68-.52-.01-.53.63-.01 1.08.58 1.23.82.72 1.21 1.87.87 2.33.66.07-.52.28-.87.51-1.07-1.78-.2-3.64-.89-3.64-3.95 0-.87.31-1.59.82-2.15-.08-.2-.36-1.02.08-2.12 0 0 .67-.21 2.2.82.64-.18 1.32-.27 2-.27.68 0 1.36.09 2 .27 1.53-1.04 2.2-.82 2.2-.82.44 1.1.16 1.92.08 2.12.51.56.82 1.27.82 2.15 0 3.07-1.87 3.75-3.65 3.95.29.25.54.73.54 1.48 0 1.07-.01 1.93-.01 2.2 0 .21.15.46.55.38A8.013 8.013 0 0016 8c0-4.42-3.58-8-8-8z" fill="currentColor"></path></svg></a></li></ul></footer></body>


			
			<script>
				{
					__sveltekit_1kwx0yh = {
						env: {},
						base: new URL("..", location).pathname.slice(0, -1),
						element: document.currentScript.parentElement
					};

					const data = [null,{"type":"data","data":{prev:{slug:"ml\u002Fvision_transformer",title:"Vision Transformer"},next:{slug:"ml\u002Fpytorch",title:"PyTorch"},section:{file:"ml\u002F20-chat_gpt.md",title:"Learn ChatGPT from ChatGPT",date:"Feb. 3, 2023",summary:void 0,tag:["GPT","OpenAI"],toc:"\u003Ch4\u003EContents\u003C\u002Fh4\u003E\u003Cp class=\"toc-h3\"\u003E\u003Ca href=\"#understand-chatgpt-technology\"\u003EUnderstand ChatGPT Technology\u003C\u002Fa\u003E\u003C\u002Fp\u003E\u003Cp class=\"toc-h3\"\u003E\u003Ca href=\"#attention-is-all-you-need\"\u003EAttention is All you Need\u003C\u002Fa\u003E\u003C\u002Fp\u003E\u003Cp class=\"toc-h3\"\u003E\u003Ca href=\"#gpt\"\u003EGPT\u003C\u002Fa\u003E\u003C\u002Fp\u003E\u003Cp class=\"toc-h3\"\u003E\u003Ca href=\"#gpt-vs-transformer\"\u003EGPT vs. Transformer\u003C\u002Fa\u003E\u003C\u002Fp\u003E\u003Cp class=\"toc-h3\"\u003E\u003Ca href=\"#text-and-code-embeddings-by-contrastive-pre-training\"\u003EText and Code Embeddings by Contrastive Pre-Training\u003C\u002Fa\u003E\u003C\u002Fp\u003E\u003Cp class=\"toc-h3\"\u003E\u003Ca href=\"#autoregressive-model\"\u003EAutoregressive model\u003C\u002Fa\u003E\u003C\u002Fp\u003E\u003Cp class=\"toc-h3\"\u003E\u003Ca href=\"#zero-shot-learning\"\u003EZero-Shot learning\u003C\u002Fa\u003E\u003C\u002Fp\u003E\u003Cp class=\"toc-h3\"\u003E\u003Ca href=\"#min-gpt\"\u003Emin GPT\u003C\u002Fa\u003E\u003C\u002Fp\u003E\u003Cp class=\"toc-h3\"\u003E\u003Ca href=\"#pros-and-cons\"\u003EPros and Cons\u003C\u002Fa\u003E\u003C\u002Fp\u003E",body:"\u003Ch3 id=\"understand-chatgpt-technology\"\u003EUnderstand ChatGPT Technology\u003Ca href=\"#understand-chatgpt-technology\" class=\"anchor\"\u003E\u003Cspan class=\"visually-hidden\"\u003E#\u003C\u002Fspan\u003E\u003C\u002Fa\u003E\u003C\u002Fh3\u003E\u003Cp\u003EChatGPT is a conversational AI model developed by OpenAI. It’s based on the Transformer architecture and is trained on a large corpus of text data to generate human-like responses to text-based inputs. To understand ChatGPT, you should know the following basics:\u003C\u002Fp\u003E\n\u003Col\u003E\n\u003Cli\u003ENatural Language Processing (NLP): ChatGPT uses NLP techniques to understand and generate human language.\u003C\u002Fli\u003E\n\u003Cli\u003EMachine learning: ChatGPT is a machine learning model that uses supervised learning to generate text responses.\u003C\u002Fli\u003E\n\u003Cli\u003ETransformer architecture: This is a neural network architecture used in NLP tasks that was introduced in the 2017 paper “Attention is All You Need”.\u003C\u002Fli\u003E\n\u003Cli\u003EPre-training: ChatGPT is a pre-trained model that was fine-tuned on a large corpus of text data to generate text responses.\u003C\u002Fli\u003E\n\u003Cli\u003EFine-tuning: This is the process of training a pre-trained model on a smaller, specific task-specific dataset to adapt it to a particular use case.\u003C\u002Fli\u003E\n\u003Cli\u003EGenerative model: ChatGPT is a generative model, which means it generates text rather than simply classifying or translating it.\u003C\u002Fli\u003E\n\u003Cli\u003ELanguage generation: ChatGPT uses probabilistic language generation techniques to generate text responses that are contextually relevant to the input prompt.\u003C\u002Fli\u003E\n\u003C\u002Fol\u003E\n\u003Ch3 id=\"attention-is-all-you-need\"\u003EAttention is All you Need\u003Ca href=\"#attention-is-all-you-need\" class=\"anchor\"\u003E\u003Cspan class=\"visually-hidden\"\u003E#\u003C\u002Fspan\u003E\u003C\u002Fa\u003E\u003C\u002Fh3\u003E\u003Cp\u003EThe authors argue that attention mechanisms are sufficient for building deep learning models for NLP tasks, such as machine translation, and that these models can be trained effectively in an end-to-end manner.\u003C\u002Fp\u003E\n\u003Cp\u003E\u003Cstrong\u003ESelf-attention mechanisms\u003C\u002Fstrong\u003E allow the model to selectively focus on different parts of the input sequence. This allows the model to process input sequences in parallel, which makes it faster and more parallelizable than RNNs.\u003C\u002Fp\u003E\n\u003Cp\u003EThe Transformer architecture also introduced the concept of \u003Cstrong\u003Emulti-head attention\u003C\u002Fstrong\u003E, which allows the model to attend to different parts of the input sequence in multiple ways, and \u003Cstrong\u003Ethe position encoding mechanism\u003C\u002Fstrong\u003E, which encodes the relative position of words in a sentence.\u003C\u002Fp\u003E\n\u003Ch3 id=\"gpt\"\u003EGPT\u003Ca href=\"#gpt\" class=\"anchor\"\u003E\u003Cspan class=\"visually-hidden\"\u003E#\u003C\u002Fspan\u003E\u003C\u002Fa\u003E\u003C\u002Fh3\u003E\u003Cp\u003EGPT stands for \u003Cstrong\u003EGenerative Pretrained Transformer\u003C\u002Fstrong\u003E, which is a language generation model developed by OpenAI.\u003C\u002Fp\u003E\n\u003Cp\u003EGPT uses a large corpus of text data to pre-train a deep neural network on the task of \u003Cstrong\u003Epredicting the next word in a sentence\u003C\u002Fstrong\u003E. The pre-training allows the model \u003Cstrong\u003Eto learn general language patterns and relationships\u003C\u002Fstrong\u003E, so that it can generate text that is similar to the training data.\u003C\u002Fp\u003E\n\u003Ch3 id=\"gpt-vs-transformer\"\u003EGPT vs. Transformer\u003Ca href=\"#gpt-vs-transformer\" class=\"anchor\"\u003E\u003Cspan class=\"visually-hidden\"\u003E#\u003C\u002Fspan\u003E\u003C\u002Fa\u003E\u003C\u002Fh3\u003E\u003Cul\u003E\n\u003Cli\u003EThe Transformer architecture is a type of neural network that can be used for various NLP tasks.\u003C\u002Fli\u003E\n\u003Cli\u003EGPT is a specific pre-trained language generation model based on the Transformer architecture.\u003C\u002Fli\u003E\n\u003C\u002Ful\u003E\n\u003Cdiv class=\"code-block python\"\u003E\u003Cpre class='language-python'\u003E\u003Ccode\u003E\u003Cspan class=\"token comment\"\u003E# Simple implementation of Transformer\u003C\u002Fspan\u003E\n\u003Cspan class=\"token keyword\"\u003Eimport\u003C\u002Fspan\u003E torch\n\u003Cspan class=\"token keyword\"\u003Eimport\u003C\u002Fspan\u003E torch\u003Cspan class=\"token punctuation\"\u003E.\u003C\u002Fspan\u003Enn \u003Cspan class=\"token keyword\"\u003Eas\u003C\u002Fspan\u003E nn\n\u003Cspan class=\"token keyword\"\u003Eimport\u003C\u002Fspan\u003E torch\u003Cspan class=\"token punctuation\"\u003E.\u003C\u002Fspan\u003Enn\u003Cspan class=\"token punctuation\"\u003E.\u003C\u002Fspan\u003Efunctional \u003Cspan class=\"token keyword\"\u003Eas\u003C\u002Fspan\u003E F\n\n\u003Cspan class=\"token keyword\"\u003Eclass\u003C\u002Fspan\u003E \u003Cspan class=\"token class-name\"\u003ETransformer\u003C\u002Fspan\u003E\u003Cspan class=\"token punctuation\"\u003E(\u003C\u002Fspan\u003Enn\u003Cspan class=\"token punctuation\"\u003E.\u003C\u002Fspan\u003EModule\u003Cspan class=\"token punctuation\"\u003E)\u003C\u002Fspan\u003E\u003Cspan class=\"token punctuation\"\u003E:\u003C\u002Fspan\u003E\n    \u003Cspan class=\"token keyword\"\u003Edef\u003C\u002Fspan\u003E \u003Cspan class=\"token function\"\u003E__init__\u003C\u002Fspan\u003E\u003Cspan class=\"token punctuation\"\u003E(\u003C\u002Fspan\u003Eself\u003Cspan class=\"token punctuation\"\u003E,\u003C\u002Fspan\u003E d_model\u003Cspan class=\"token punctuation\"\u003E,\u003C\u002Fspan\u003E nhead\u003Cspan class=\"token punctuation\"\u003E,\u003C\u002Fspan\u003E num_encoder_layers\u003Cspan class=\"token punctuation\"\u003E,\u003C\u002Fspan\u003E num_decoder_layers\u003Cspan class=\"token punctuation\"\u003E,\u003C\u002Fspan\u003E dim_feedforward\u003Cspan class=\"token punctuation\"\u003E,\u003C\u002Fspan\u003E dropout\u003Cspan class=\"token operator\"\u003E=\u003C\u002Fspan\u003E\u003Cspan class=\"token number\"\u003E0.1\u003C\u002Fspan\u003E\u003Cspan class=\"token punctuation\"\u003E)\u003C\u002Fspan\u003E\u003Cspan class=\"token punctuation\"\u003E:\u003C\u002Fspan\u003E\n        \u003Cspan class=\"token builtin\"\u003Esuper\u003C\u002Fspan\u003E\u003Cspan class=\"token punctuation\"\u003E(\u003C\u002Fspan\u003ETransformer\u003Cspan class=\"token punctuation\"\u003E,\u003C\u002Fspan\u003E self\u003Cspan class=\"token punctuation\"\u003E)\u003C\u002Fspan\u003E\u003Cspan class=\"token punctuation\"\u003E.\u003C\u002Fspan\u003E__init__\u003Cspan class=\"token punctuation\"\u003E(\u003C\u002Fspan\u003E\u003Cspan class=\"token punctuation\"\u003E)\u003C\u002Fspan\u003E\n\n        self\u003Cspan class=\"token punctuation\"\u003E.\u003C\u002Fspan\u003Eencoder_layer \u003Cspan class=\"token operator\"\u003E=\u003C\u002Fspan\u003E nn\u003Cspan class=\"token punctuation\"\u003E.\u003C\u002Fspan\u003ETransformerEncoderLayer\u003Cspan class=\"token punctuation\"\u003E(\u003C\u002Fspan\u003Ed_model\u003Cspan class=\"token punctuation\"\u003E,\u003C\u002Fspan\u003E nhead\u003Cspan class=\"token punctuation\"\u003E,\u003C\u002Fspan\u003E dim_feedforward\u003Cspan class=\"token punctuation\"\u003E,\u003C\u002Fspan\u003E dropout\u003Cspan class=\"token punctuation\"\u003E)\u003C\u002Fspan\u003E\n        self\u003Cspan class=\"token punctuation\"\u003E.\u003C\u002Fspan\u003Etransformer_encoder \u003Cspan class=\"token operator\"\u003E=\u003C\u002Fspan\u003E nn\u003Cspan class=\"token punctuation\"\u003E.\u003C\u002Fspan\u003ETransformerEncoder\u003Cspan class=\"token punctuation\"\u003E(\u003C\u002Fspan\u003Eself\u003Cspan class=\"token punctuation\"\u003E.\u003C\u002Fspan\u003Eencoder_layer\u003Cspan class=\"token punctuation\"\u003E,\u003C\u002Fspan\u003E num_encoder_layers\u003Cspan class=\"token punctuation\"\u003E)\u003C\u002Fspan\u003E\n\n        self\u003Cspan class=\"token punctuation\"\u003E.\u003C\u002Fspan\u003Edecoder_layer \u003Cspan class=\"token operator\"\u003E=\u003C\u002Fspan\u003E nn\u003Cspan class=\"token punctuation\"\u003E.\u003C\u002Fspan\u003ETransformerDecoderLayer\u003Cspan class=\"token punctuation\"\u003E(\u003C\u002Fspan\u003Ed_model\u003Cspan class=\"token punctuation\"\u003E,\u003C\u002Fspan\u003E nhead\u003Cspan class=\"token punctuation\"\u003E,\u003C\u002Fspan\u003E dim_feedforward\u003Cspan class=\"token punctuation\"\u003E,\u003C\u002Fspan\u003E dropout\u003Cspan class=\"token punctuation\"\u003E)\u003C\u002Fspan\u003E\n        self\u003Cspan class=\"token punctuation\"\u003E.\u003C\u002Fspan\u003Etransformer_decoder \u003Cspan class=\"token operator\"\u003E=\u003C\u002Fspan\u003E nn\u003Cspan class=\"token punctuation\"\u003E.\u003C\u002Fspan\u003ETransformerDecoder\u003Cspan class=\"token punctuation\"\u003E(\u003C\u002Fspan\u003Eself\u003Cspan class=\"token punctuation\"\u003E.\u003C\u002Fspan\u003Edecoder_layer\u003Cspan class=\"token punctuation\"\u003E,\u003C\u002Fspan\u003E num_decoder_layers\u003Cspan class=\"token punctuation\"\u003E)\u003C\u002Fspan\u003E\n\n    \u003Cspan class=\"token keyword\"\u003Edef\u003C\u002Fspan\u003E \u003Cspan class=\"token function\"\u003Eforward\u003C\u002Fspan\u003E\u003Cspan class=\"token punctuation\"\u003E(\u003C\u002Fspan\u003Eself\u003Cspan class=\"token punctuation\"\u003E,\u003C\u002Fspan\u003E src\u003Cspan class=\"token punctuation\"\u003E,\u003C\u002Fspan\u003E tgt\u003Cspan class=\"token punctuation\"\u003E,\u003C\u002Fspan\u003E src_mask\u003Cspan class=\"token operator\"\u003E=\u003C\u002Fspan\u003E\u003Cspan class=\"token boolean\"\u003ENone\u003C\u002Fspan\u003E\u003Cspan class=\"token punctuation\"\u003E,\u003C\u002Fspan\u003E tgt_mask\u003Cspan class=\"token operator\"\u003E=\u003C\u002Fspan\u003E\u003Cspan class=\"token boolean\"\u003ENone\u003C\u002Fspan\u003E\u003Cspan class=\"token punctuation\"\u003E,\u003C\u002Fspan\u003E memory_mask\u003Cspan class=\"token operator\"\u003E=\u003C\u002Fspan\u003E\u003Cspan class=\"token boolean\"\u003ENone\u003C\u002Fspan\u003E\u003Cspan class=\"token punctuation\"\u003E,\u003C\u002Fspan\u003E src_key_padding_mask\u003Cspan class=\"token operator\"\u003E=\u003C\u002Fspan\u003E\u003Cspan class=\"token boolean\"\u003ENone\u003C\u002Fspan\u003E\u003Cspan class=\"token punctuation\"\u003E,\u003C\u002Fspan\u003E tgt_key_padding_mask\u003Cspan class=\"token operator\"\u003E=\u003C\u002Fspan\u003E\u003Cspan class=\"token boolean\"\u003ENone\u003C\u002Fspan\u003E\u003Cspan class=\"token punctuation\"\u003E,\u003C\u002Fspan\u003E memory_key_padding_mask\u003Cspan class=\"token operator\"\u003E=\u003C\u002Fspan\u003E\u003Cspan class=\"token boolean\"\u003ENone\u003C\u002Fspan\u003E\u003Cspan class=\"token punctuation\"\u003E)\u003C\u002Fspan\u003E\u003Cspan class=\"token punctuation\"\u003E:\u003C\u002Fspan\u003E\n        memory \u003Cspan class=\"token operator\"\u003E=\u003C\u002Fspan\u003E self\u003Cspan class=\"token punctuation\"\u003E.\u003C\u002Fspan\u003Etransformer_encoder\u003Cspan class=\"token punctuation\"\u003E(\u003C\u002Fspan\u003Esrc\u003Cspan class=\"token punctuation\"\u003E,\u003C\u002Fspan\u003E src_mask\u003Cspan class=\"token punctuation\"\u003E)\u003C\u002Fspan\u003E\n        output \u003Cspan class=\"token operator\"\u003E=\u003C\u002Fspan\u003E self\u003Cspan class=\"token punctuation\"\u003E.\u003C\u002Fspan\u003Etransformer_decoder\u003Cspan class=\"token punctuation\"\u003E(\u003C\u002Fspan\u003Etgt\u003Cspan class=\"token punctuation\"\u003E,\u003C\u002Fspan\u003E memory\u003Cspan class=\"token punctuation\"\u003E,\u003C\u002Fspan\u003E tgt_mask\u003Cspan class=\"token punctuation\"\u003E,\u003C\u002Fspan\u003E memory_mask\u003Cspan class=\"token punctuation\"\u003E)\u003C\u002Fspan\u003E\n        \u003Cspan class=\"token keyword\"\u003Ereturn\u003C\u002Fspan\u003E output\u003C\u002Fcode\u003E\u003C\u002Fpre\u003E\u003C\u002Fdiv\u003E\u003Cdiv class=\"code-block python\"\u003E\u003Cpre class='language-python'\u003E\u003Ccode\u003E\u003Cspan class=\"token comment\"\u003E# Simple implementation of GPT-1\u003C\u002Fspan\u003E\n\u003Cspan class=\"token keyword\"\u003Eimport\u003C\u002Fspan\u003E torch\n\u003Cspan class=\"token keyword\"\u003Eimport\u003C\u002Fspan\u003E torch\u003Cspan class=\"token punctuation\"\u003E.\u003C\u002Fspan\u003Enn \u003Cspan class=\"token keyword\"\u003Eas\u003C\u002Fspan\u003E nn\n\u003Cspan class=\"token keyword\"\u003Eimport\u003C\u002Fspan\u003E torch\u003Cspan class=\"token punctuation\"\u003E.\u003C\u002Fspan\u003Enn\u003Cspan class=\"token punctuation\"\u003E.\u003C\u002Fspan\u003Efunctional \u003Cspan class=\"token keyword\"\u003Eas\u003C\u002Fspan\u003E F\n\n\u003Cspan class=\"token keyword\"\u003Eclass\u003C\u002Fspan\u003E \u003Cspan class=\"token class-name\"\u003EGPT1\u003C\u002Fspan\u003E\u003Cspan class=\"token punctuation\"\u003E(\u003C\u002Fspan\u003Enn\u003Cspan class=\"token punctuation\"\u003E.\u003C\u002Fspan\u003EModule\u003Cspan class=\"token punctuation\"\u003E)\u003C\u002Fspan\u003E\u003Cspan class=\"token punctuation\"\u003E:\u003C\u002Fspan\u003E\n    \u003Cspan class=\"token keyword\"\u003Edef\u003C\u002Fspan\u003E \u003Cspan class=\"token function\"\u003E__init__\u003C\u002Fspan\u003E\u003Cspan class=\"token punctuation\"\u003E(\u003C\u002Fspan\u003Eself\u003Cspan class=\"token punctuation\"\u003E,\u003C\u002Fspan\u003E vocab_size\u003Cspan class=\"token punctuation\"\u003E,\u003C\u002Fspan\u003E d_model\u003Cspan class=\"token punctuation\"\u003E,\u003C\u002Fspan\u003E nhead\u003Cspan class=\"token punctuation\"\u003E,\u003C\u002Fspan\u003E num_layers\u003Cspan class=\"token punctuation\"\u003E,\u003C\u002Fspan\u003E dim_feedforward\u003Cspan class=\"token punctuation\"\u003E,\u003C\u002Fspan\u003E dropout\u003Cspan class=\"token operator\"\u003E=\u003C\u002Fspan\u003E\u003Cspan class=\"token number\"\u003E0.1\u003C\u002Fspan\u003E\u003Cspan class=\"token punctuation\"\u003E)\u003C\u002Fspan\u003E\u003Cspan class=\"token punctuation\"\u003E:\u003C\u002Fspan\u003E\n        \u003Cspan class=\"token builtin\"\u003Esuper\u003C\u002Fspan\u003E\u003Cspan class=\"token punctuation\"\u003E(\u003C\u002Fspan\u003EGPT1\u003Cspan class=\"token punctuation\"\u003E,\u003C\u002Fspan\u003E self\u003Cspan class=\"token punctuation\"\u003E)\u003C\u002Fspan\u003E\u003Cspan class=\"token punctuation\"\u003E.\u003C\u002Fspan\u003E__init__\u003Cspan class=\"token punctuation\"\u003E(\u003C\u002Fspan\u003E\u003Cspan class=\"token punctuation\"\u003E)\u003C\u002Fspan\u003E\n\n        self\u003Cspan class=\"token punctuation\"\u003E.\u003C\u002Fspan\u003Eembedding \u003Cspan class=\"token operator\"\u003E=\u003C\u002Fspan\u003E nn\u003Cspan class=\"token punctuation\"\u003E.\u003C\u002Fspan\u003EEmbedding\u003Cspan class=\"token punctuation\"\u003E(\u003C\u002Fspan\u003Evocab_size\u003Cspan class=\"token punctuation\"\u003E,\u003C\u002Fspan\u003E d_model\u003Cspan class=\"token punctuation\"\u003E)\u003C\u002Fspan\u003E\n        self\u003Cspan class=\"token punctuation\"\u003E.\u003C\u002Fspan\u003Etransformer \u003Cspan class=\"token operator\"\u003E=\u003C\u002Fspan\u003E nn\u003Cspan class=\"token punctuation\"\u003E.\u003C\u002Fspan\u003ETransformer\u003Cspan class=\"token punctuation\"\u003E(\u003C\u002Fspan\u003Ed_model\u003Cspan class=\"token punctuation\"\u003E,\u003C\u002Fspan\u003E nhead\u003Cspan class=\"token punctuation\"\u003E,\u003C\u002Fspan\u003E num_layers\u003Cspan class=\"token punctuation\"\u003E,\u003C\u002Fspan\u003E dim_feedforward\u003Cspan class=\"token punctuation\"\u003E,\u003C\u002Fspan\u003E dropout\u003Cspan class=\"token punctuation\"\u003E)\u003C\u002Fspan\u003E\n        self\u003Cspan class=\"token punctuation\"\u003E.\u003C\u002Fspan\u003Efc \u003Cspan class=\"token operator\"\u003E=\u003C\u002Fspan\u003E nn\u003Cspan class=\"token punctuation\"\u003E.\u003C\u002Fspan\u003ELinear\u003Cspan class=\"token punctuation\"\u003E(\u003C\u002Fspan\u003Ed_model\u003Cspan class=\"token punctuation\"\u003E,\u003C\u002Fspan\u003E vocab_size\u003Cspan class=\"token punctuation\"\u003E)\u003C\u002Fspan\u003E\n\n    \u003Cspan class=\"token keyword\"\u003Edef\u003C\u002Fspan\u003E \u003Cspan class=\"token function\"\u003Eforward\u003C\u002Fspan\u003E\u003Cspan class=\"token punctuation\"\u003E(\u003C\u002Fspan\u003Eself\u003Cspan class=\"token punctuation\"\u003E,\u003C\u002Fspan\u003E x\u003Cspan class=\"token punctuation\"\u003E)\u003C\u002Fspan\u003E\u003Cspan class=\"token punctuation\"\u003E:\u003C\u002Fspan\u003E\n        x \u003Cspan class=\"token operator\"\u003E=\u003C\u002Fspan\u003E self\u003Cspan class=\"token punctuation\"\u003E.\u003C\u002Fspan\u003Eembedding\u003Cspan class=\"token punctuation\"\u003E(\u003C\u002Fspan\u003Ex\u003Cspan class=\"token punctuation\"\u003E)\u003C\u002Fspan\u003E\n        x \u003Cspan class=\"token operator\"\u003E=\u003C\u002Fspan\u003E self\u003Cspan class=\"token punctuation\"\u003E.\u003C\u002Fspan\u003Etransformer\u003Cspan class=\"token punctuation\"\u003E(\u003C\u002Fspan\u003Ex\u003Cspan class=\"token punctuation\"\u003E)\u003C\u002Fspan\u003E\n        x \u003Cspan class=\"token operator\"\u003E=\u003C\u002Fspan\u003E self\u003Cspan class=\"token punctuation\"\u003E.\u003C\u002Fspan\u003Efc\u003Cspan class=\"token punctuation\"\u003E(\u003C\u002Fspan\u003Ex\u003Cspan class=\"token punctuation\"\u003E)\u003C\u002Fspan\u003E\n        \u003Cspan class=\"token keyword\"\u003Ereturn\u003C\u002Fspan\u003E x\u003C\u002Fcode\u003E\u003C\u002Fpre\u003E\u003C\u002Fdiv\u003E\u003Ch3 id=\"text-and-code-embeddings-by-contrastive-pre-training\"\u003EText and Code Embeddings by Contrastive Pre-Training\u003Ca href=\"#text-and-code-embeddings-by-contrastive-pre-training\" class=\"anchor\"\u003E\u003Cspan class=\"visually-hidden\"\u003E#\u003C\u002Fspan\u003E\u003C\u002Fa\u003E\u003C\u002Fh3\u003E\u003Cp\u003EPaper: \u003C\u002Fp\u003E\n\u003Cp\u003EThe paper proposes a novel pre-training method for learning text and code embeddings. The main idea behind the method is to use a contrastive loss function to pre-train the embeddings in an unsupervised manner.\u003C\u002Fp\u003E\n\u003Cp\u003EThe loss function used for this prediction task is a contrastive loss function that encourages the embeddings of similar tokens (e.g., tokens with similar meanings) to be close together in the embedding space, while encouraging the embeddings of dissimilar tokens to be far apart.\u003C\u002Fp\u003E\n\u003Cp\u003EZero-shot learning is a machine learning approach where a model is trained to recognize and classify new, unseen classes without any additional training data. \u003C\u002Fp\u003E\n\u003Ch3 id=\"autoregressive-model\"\u003EAutoregressive model\u003Ca href=\"#autoregressive-model\" class=\"anchor\"\u003E\u003Cspan class=\"visually-hidden\"\u003E#\u003C\u002Fspan\u003E\u003C\u002Fa\u003E\u003C\u002Fh3\u003E\u003Cp\u003EAn autoregressive model is a type of statistical model that is used for time series forecasting and sequence generation tasks. In an autoregressive model, the current output or prediction is a function of previous inputs or outputs in the sequence.\u003C\u002Fp\u003E\n\u003Cp\u003EThe most common form of an autoregressive model is the Autoregressive Integrated Moving Average (ARIMA) model, which is used in time series analysis to model the dependencies between observations over time. ARIMA models can be used to perform various tasks, such as prediction of future values, identifying trends and patterns in time series data, and modeling the impact of past events on future outcomes.\u003C\u002Fp\u003E\n\u003Cp\u003EIn the field of machine learning and artificial neural networks, autoregressive models are used for sequence generation tasks, such as text generation and music composition.\u003C\u002Fp\u003E\n\u003Ch3 id=\"zero-shot-learning\"\u003EZero-Shot learning\u003Ca href=\"#zero-shot-learning\" class=\"anchor\"\u003E\u003Cspan class=\"visually-hidden\"\u003E#\u003C\u002Fspan\u003E\u003C\u002Fa\u003E\u003C\u002Fh3\u003E\u003Cp\u003EThe goal of zero-shot learning is to learn a model that can generalize to new classes based on prior knowledge or information about the relationships between classes, without the need for additional labeled examples of those classes.\u003C\u002Fp\u003E\n\u003Cp\u003EIn zero-shot learning, a model is typically trained on a set of source classes and \u003Cstrong\u003Ea semantic representation\u003C\u002Fstrong\u003E of each class is obtained.\u003C\u002Fp\u003E\n\u003Cp\u003EZero-shot learning is a challenging problem in machine learning, and it is particularly useful for applications where it is not feasible to collect labeled data for every class. For example, in computer vision, zero-shot learning can be used to recognize and classify new species of animals or plants without the need for labeled images of those species.\u003C\u002Fp\u003E\n\u003Cp\u003Ee.g. \u003Cspan class=\"katex\"\u003E\u003Cspan class=\"katex-mathml\"\u003E\u003Cmath xmlns=\"http:\u002F\u002Fwww.w3.org\u002F1998\u002FMath\u002FMathML\"\u003E\u003Csemantics\u003E\u003Cmrow\u003E\u003Cmtext\u003Ezebras\u003C\u002Fmtext\u003E\u003Cmo\u003E=\u003C\u002Fmo\u003E\u003Cmtext\u003Estriped\u003C\u002Fmtext\u003E\u003Cmo\u003E+\u003C\u002Fmo\u003E\u003Cmtext\u003Ehorses\u003C\u002Fmtext\u003E\u003C\u002Fmrow\u003E\u003Cannotation encoding=\"application\u002Fx-tex\"\u003E\\text{zebras} = \\text{striped} + \\text{horses}\u003C\u002Fannotation\u003E\u003C\u002Fsemantics\u003E\u003C\u002Fmath\u003E\u003C\u002Fspan\u003E\u003Cspan class=\"katex-html\" aria-hidden=\"true\"\u003E\u003Cspan class=\"base\"\u003E\u003Cspan class=\"strut\" style=\"height:0.6944em;\"\u003E\u003C\u002Fspan\u003E\u003Cspan class=\"mord text\"\u003E\u003Cspan class=\"mord\"\u003Ezebras\u003C\u002Fspan\u003E\u003C\u002Fspan\u003E\u003Cspan class=\"mspace\" style=\"margin-right:0.2778em;\"\u003E\u003C\u002Fspan\u003E\u003Cspan class=\"mrel\"\u003E=\u003C\u002Fspan\u003E\u003Cspan class=\"mspace\" style=\"margin-right:0.2778em;\"\u003E\u003C\u002Fspan\u003E\u003C\u002Fspan\u003E\u003Cspan class=\"base\"\u003E\u003Cspan class=\"strut\" style=\"height:0.8889em;vertical-align:-0.1944em;\"\u003E\u003C\u002Fspan\u003E\u003Cspan class=\"mord text\"\u003E\u003Cspan class=\"mord\"\u003Estriped\u003C\u002Fspan\u003E\u003C\u002Fspan\u003E\u003Cspan class=\"mspace\" style=\"margin-right:0.2222em;\"\u003E\u003C\u002Fspan\u003E\u003Cspan class=\"mbin\"\u003E+\u003C\u002Fspan\u003E\u003Cspan class=\"mspace\" style=\"margin-right:0.2222em;\"\u003E\u003C\u002Fspan\u003E\u003C\u002Fspan\u003E\u003Cspan class=\"base\"\u003E\u003Cspan class=\"strut\" style=\"height:0.6944em;\"\u003E\u003C\u002Fspan\u003E\u003Cspan class=\"mord text\"\u003E\u003Cspan class=\"mord\"\u003Ehorses\u003C\u002Fspan\u003E\u003C\u002Fspan\u003E\u003C\u002Fspan\u003E\u003C\u002Fspan\u003E\u003C\u002Fspan\u003E\u003C\u002Fp\u003E\n\u003Chr\u003E\n\u003Cp\u003ENot from ChatGPT\u003C\u002Fp\u003E\n\u003Ch3 id=\"min-gpt\"\u003Emin GPT\u003Ca href=\"#min-gpt\" class=\"anchor\"\u003E\u003Cspan class=\"visually-hidden\"\u003E#\u003C\u002Fspan\u003E\u003C\u002Fa\u003E\u003C\u002Fh3\u003E\u003Cp\u003E\u003Ca href=\"https:\u002F\u002Fgithub.com\u002Fkarpathy\u002FminGPT\u002Fblob\u002Fmaster\u002Fmingpt\u002Fmodel.py\"\u003Ehttps:\u002F\u002Fgithub.com\u002Fkarpathy\u002FminGPT\u002Fblob\u002Fmaster\u002Fmingpt\u002Fmodel.py\u003C\u002Fa\u003E\u003C\u002Fp\u003E\n\u003Ch3 id=\"pros-and-cons\"\u003EPros and Cons\u003Ca href=\"#pros-and-cons\" class=\"anchor\"\u003E\u003Cspan class=\"visually-hidden\"\u003E#\u003C\u002Fspan\u003E\u003C\u002Fa\u003E\u003C\u002Fh3\u003E\u003Cul\u003E\n\u003Cli\u003E\u003Cp\u003Etoo generalized &lt;–&gt; more proper answers for everyone\u003C\u002Fp\u003E\n\u003C\u002Fli\u003E\n\u003Cli\u003E\u003C\u002Fli\u003E\n\u003C\u002Ful\u003E\n"}},"uses":{"params":["path","slug"]}}];

					Promise.all([
						import("../_app/immutable/entry/start.515f0d26.js"),
						import("../_app/immutable/entry/app.8b861ad3.js")
					]).then(([kit, app]) => {
						kit.start(app, __sveltekit_1kwx0yh.element, {
							node_ids: [0, 4],
							data,
							form: null,
							error: null
						});
					});
				}
			</script>
		</div>
	</body>
</html>
